{
  "training": {
    "optimizer": "adam",
    "clip_c": 1,
    "lrate": 0.001,
    "epochs": 30
  },
  "management": {
    "monitor_loss": 1000,
    "checkpoint_freq": 10,
    "print_samples": false,
    "evaluate": false
  },
  "data": {
    "src": "/mnt/sdb1/git_code/StoryGeneration/Event2Sentence/Data/generalEventTrain_input.txt",
    "trg": "/mnt/sdb1/git_code/StoryGeneration/Event2Sentence/Data/generalEventTrain_output.txt",
    "test_src": "/mnt/sdb1/git_code/StoryGeneration/Event2Sentence/Data/generalEventTest_input.txt",
    "test_trg": "/mnt/sdb1/git_code/StoryGeneration/Event2Sentence/Data/generalEventTest_output.txt",
    "batch_size": 80,
    "n_words_trg": 30000,
    "valid_batch_size": 80,
    "n_words_src": 30000,
    "max_src_length": 4,
    "max_trg_length": 4,
    "task": "translation",
    "save_dir": "/mnt/sdb1/git_code/StoryGeneration/Event2Sentence/Models",
    "load_dir": false,
    "preload_weights": "model_translation__src_AllGenEvents__trg_GenSents__attention_attention__dim_1024__emb_dim_1024__optimizer_adam__n_layers_src_3__n_layers_trg_1__bidir_True__epoch_final30.model"
  },
  "model": {
    "dim": 512,
    "dim_trg": 512,
    "use_dropout": false,
    "dim_word_src": 512,
    "n_words_src": 30000,
    "n_words": 30000,
    "dim_word_trg": 512,
    "n_layers_src": 3,
    "n_layers_trg": 1,
    "bidirectional": false,
    "src_type": "genEvents",
    "trg_type": "genEvents",
    "decode": "beam_search",
    "beam_size": 5,
    "seq2seq": "attention",
    "optimizer": "adam"
  }
}

